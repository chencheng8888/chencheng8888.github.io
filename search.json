[{"title":"singleflight源码解读","url":"/2025/05/17/singleflight源码解读/","content":"singleflight源码解读使用Singleflight的目的：解决缓存击穿 什么是缓存击穿？缓存击穿简单来说，就是热点Key失效后，如果突然出现大量请求就会直达数据库，造成数据库负载升高 可能想的一个解决办法是，只允许一个请求访问数据库，并把数据回填到缓存中，后续请求访问缓存即可 而singleflight基本就是这个思路，多个并发请求到来，只有第一个协程执行任务，在将结果复用给其他协程 代码 Group但是，这次，出于我本人的好奇，我想看看singleflight具体是如何实现的，而且其源码也不长，总共200多行 首先，我们先看看Group 这个类型，他拥有Do这个方法 结构上还是很简单的，大体上就是使用一个map来保存不同key的请求，然后使用sync.Mutex来保护map，防止并发读写 call接下来我们看看call及其子类型 暂时，我们只是了解了这些类型有哪些字段，但字段的用途可能还有些不了解，别急，我们接着看 Do我们看看最主要的Do方法，具体的解释，我写在源码中 其实还有个DoChan方法，但和Do方法不同的是，他返回的是一个channel，当第一个gorountine执行完后，就会往每一个正在等待的gorountine的channel中放入值","date":"2025-05-17","categories":["golang"],"tags":["golang","singleflight"]},{"title":"Casbin","url":"/2025/05/05/casbin/","content":"Casbin 访问控制框架详解一、PERM 元模型Casbin 的核心是一个基于 PERM 元模型（Policy, Effect, Request, Matcher）的访问控制框架。它将授权逻辑抽象为配置文件，使得切换或升级授权机制只需修改配置即可。开发者可以通过组合不同的模型组件来自定义访问控制策略。 PERM 模型由四个核心组件构成： Policy（策略）：定义访问控制规则 Effect（效果）：定义规则匹配后的决策逻辑 Request（请求）：定义访问请求的格式 Matcher（匹配器）：定义请求与策略的匹配规则 这些组件共同描述了系统中主体（用户）与资源之间的访问控制关系。 Request - 请求定义请求定义了访问控制系统的输入格式，通常是一个三元组： sub (subject)：访问主体，通常是用户或角色 obj (object)：被访问的资源 act (action)：请求的操作类型 在配置文件中表示为：r = sub, obj, act。例如一个读取文件的请求可以表示为 (alice, data1, read)。 Policy - 策略定义策略是Casbin中的核心规则集合，定义了具体的访问控制逻辑。策略规则有两种基本格式： 基础格式：p = sub, obj, act 带决策结果的格式：p = sub, obj, act, eft (eft表示effect) 重要说明： 如果未定义eft字段，则默认策略结果为allow（允许） 每条策略明确规定了哪些主体(sub)可以对哪些资源(obj)执行什么操作(act) 策略可以存储在文件或数据库中，支持多种存储适配器 Matcher - 匹配器定义匹配器是Casbin的核心决策引擎，定义了请求与策略的匹配规则。一个典型的匹配器示例如下： 工作原理： 当请求进入时，Casbin会将请求(r)与所有策略(p)逐一比对 使用匹配器(m)中的逻辑表达式判断请求是否符合当前策略 如果匹配成功，则返回该策略的决策结果(p.eft) 最终决策由Effect部分根据所有匹配结果综合判断 匹配器支持丰富的表达式语法，可以组合多种条件进行复杂权限判断。举个例子：🏢 公司权限控制系统：Matcher 例子讲解（优化版）在一家公司中，存在两个文件资源： data1：普通资料 data2：敏感资料✅ 权限策略如下（Policy）：员工（employee）可以查看 data1经理（manager）可以查看 data1经理（manager）可以查看 data2👩‍💼 公司里有两个人： 小明 是员工（employee） 小红 是经理（manager）后来，小红出于业务需要，单独授权小明可以查看 data2（即添加了一个针对小明的特殊策略）❓现在的问题我们想判断请求：“小明可以查看 data2 吗？”🧠 结论小明可以访问 data2，因为他被直接授权了这条权限策略。而这个匹配成功是因为： r.sub &#x3D;&#x3D; p.sub 成立（小明 &#x3D;&#x3D; 小明） r.obj &#x3D;&#x3D; p.obj 成立（data2） r.act &#x3D;&#x3D; p.act 成立（read） Effect - 效果定义效果定义决定了如何对多个匹配结果进行逻辑组合，生成最终的访问控制决策。常见的效果定义包括： 允许优先（Allow-override）： 表示只要有一条匹配的策略结果为allow，则最终决策为允许 拒绝优先（Deny-override）： 表示只要有一条匹配的策略结果为deny，则最终决策为拒绝 优先级策略： 表示使用策略中定义的优先级来决定 效果定义支持多种逻辑组合方式，开发者可以根据业务需求选择最适合的策略。 示例分析🧨 如果加一条 deny 策略会怎样？员工不能查看data2显然匹配了多条规则 员工不能查看data2 小明可以查看data2假设我们使用这个e &#x3D; some(where(p.eft &#x3D;&#x3D; allow))对匹配器的匹配结果进行逻辑组合判断，即只要有一个规则是允许(allow)，我们就认为最终结果为真显然匹配的规则中有一条是允许的，所以我们认为结果为小明可以查看data2 二、ACL模型（访问控制列表）ACL（Access Control List）是Casbin中最基础的访问控制模型，其特点是为每个主体(subject)直接分配资源权限。模型配置包含以下核心部分： Request definition Policy definition Policy effect Matchers ACL模型的一个示例策略为： 这个ACL策略表示： alice被授予data1的read权限 bob被授予data2的write权限 ACL模型的特点： 直接为主体(subject)分配资源权限 权限管理粒度细，但维护成本高 适合小型系统或简单权限场景 与之前RBAC例子的对比： RBAC通过角色间接授权，ACL直接授权 ACL需要为每个用户单独设置权限 当用户权限变更时，ACL需要修改所有相关策略 三、RBAC模型（基于角色的访问控制）在 Casbin 中，RBAC 是在 ACL 基础上发展出来的一种模型。RBAC的核心设计理念是通过角色间接授权，相比ACL的直接授权方式具有以下优势： 权限管理更高效：通过角色组织权限，减少重复配置 职责分离更清晰：权限与具体用户解耦 扩展性更强：用户角色变更只需调整角色绑定 支持继承：角色可以继承其他角色的权限 Casbin支持RBAC与ACL混合使用，既可以通过角色授权，也可以直接为用户分配特殊权限。 Casbin的RBAC实现具有以下特点： 支持混合授权：既可以通过角色授权，也可以直接为用户分配特殊权限 灵活的策略定义：策略中的sub可以是用户或角色 高效的匹配机制：通过g(r.sub, p.sub)语法实现角色继承关系检查 在我们的例子中，为小明单独授权data2访问权限展示了Casbin的灵活性： 主体既可以通过角色获得权限（小明作为employee可以访问data1） 也可以直接获得特殊权限（小明被单独授权访问data2）那我们直接看看我们之前的例子的严格定义📄 model.conf ✅ 说明： r &#x3D; sub, obj, act：请求包括：谁、访问什么、用什么操作。 p &#x3D; sub, obj, act：策略规则，sub 可以是用户或角色。 g &#x3D; _, _：用户和角色之间的关系。 e &#x3D; some(where (p.eft &#x3D;&#x3D; allow))：只要匹配到一条允许规则，就通过。 matchers 中 (g(r.sub, p.sub) || r.sub &#x3D;&#x3D; p.sub)： 支持 RBAC（用户通过角色）✅ 也支持 ACL（用户直接授权）✅📄 policy.csv（或 policy.csv 格式的数据） 策略规则（角色级别）p, employee, data1, readp, manager, data1, readp, manager, data2, read 个体特权（ACL方式）p, 小明, data2, read 用户-角色绑定g, 小明, employeeg, 小红, manager Casbin提供了多种RBAC扩展模型，满足不同场景需求： RBAC with Pattern： 支持基于模式的资源分组 使用通配符简化策略配置 适用于资源数量多且有规律命名的场景 RBAC with Domains： 支持多租户隔离 用户在不同域可以拥有不同角色 适用于SaaS等需要租户隔离的系统 RBAC with Conditions： 支持基于条件的动态授权 可以在匹配器中添加运行时条件判断 适用于需要上下文感知的权限控制 下面详细介绍每种变种的实现方式： RBAC with Pattern 实现方式模式匹配RBAC通过以下方式简化权限管理： 模型配置： 使用keyMatch2函数实现路径模式匹配 策略示例： 核心优势： 减少策略条目：1条模式规则替代多条具体规则 动态适配：自动匹配符合模式的新资源 简化维护：资源增减无需修改策略 适用场景： RESTful API路径权限控制 文件系统目录权限管理 多层级资源权限分配 支持的模式语法： * 匹配任意字符 :variable 命名变量匹配 支持正则表达式扩展 RBAC with Domains 实现方式多租户RBAC通过以下方式实现租户隔离： 模型配置： 策略示例： 核心特性： 用户在不同租户可拥有不同角色 权限策略按租户隔离 支持跨租户的统一管理 匹配器配置： 适用场景： SaaS多租户系统 企业多部门权限隔离 多云环境权限管理 优势： 简化多租户权限管理 避免租户间权限干扰 保持权限配置的灵活性 四、ABAC（基于属性的访问控制）ABAC（Attribute-Based Access Control）是一种基于属性而非固定规则的访问控制模型。相比RBAC和ACL，ABAC具有以下特点： 动态授权：权限决策基于运行时属性 细粒度控制：支持复杂条件判断 上下文感知：可以考虑环境因素 Casbin的ABAC实现方式： 使用结构体&#x2F;类实例代替字符串 通过反射访问对象属性 支持自定义属性匹配逻辑 ABAC 实现示例 模型配置： 资源结构定义（Go示例）： 使用方式： 核心优势： 无需预先定义大量ACL规则 权限自动适应资源属性变化 支持更复杂的属性判断逻辑 典型应用场景： 文档管理系统 资源所有权验证 基于属性的动态授权 五、规则存储与适配器Casbin支持多种存储后端，通过适配器(Adapter)实现： 内置适配器： 文件适配器（默认） 内存适配器 数据库适配器： GORM适配器（支持MySQL&#x2F;PostgreSQL等） XORM适配器 MongoDB适配器 云服务适配器： Redis适配器 Etcd适配器 自定义适配器：开发者可以轻松实现自己的存储适配器 使用示例（GORM适配器）： 最佳实践： 生产环境推荐使用数据库适配器 频繁变更的策略适合使用Redis等内存数据库 分布式系统建议使用Etcd等分布式存储 更多存储方案参考官方文档：https://casbin.org/zh/docs/overview","date":"2025-05-05","categories":["casbin"],"tags":["casbin"]},{"title":"搭建k8s集群","url":"/2025/04/19/k8s_build/","content":"搭建k8s集群 注意，1-5步需要在master和node结点上都运行 ubuntu配置k8s集群 这里我也推荐下几个我看到的教程，你们失败的话，可以参考 https://zhuanlan.zhihu.com/p/560557852 https://www.cnblogs.com/Sunzz/p/15184167.html 1.环境配置1.1 配置hosts 添加你结点的地址信息，比如我的是 1.2 关闭swap分区[一定要做] 1.3 禁用selinux（一般是默认禁用的） 1.4 允许 iptables 检查桥接流量 1.5 加载ip_vs内核模块 2.安装docker 【温馨提示】dockerd 实际真实调用的还是 containerd 的 api 接口，containerd 是 dockerd 和 runC 之间的一个中间交流组件。所以启动 docker 服务的时候，也会启动 containerd 服务的。 kubernets 自ｖ 1.24.0 后，就不再使用 docker.shim，替换采用 containerd 作为容器运行时端点。因此需要安装 containerd（在 docker 的基础下安装），上面安装 docker 的时候就自动安装了 containerd 了。这里的 docker 只是作为客户端而已。容器引擎还是 containerd。 3.配置containerd 安装cri-dockerd【可忽略，如果要使用docker作为CRI，就需要，但是我还是推荐使用docker底层使用的containerd，也是k8s推荐的】Docker Engine 没有实现 CRI， 而这是容器运行时在 Kubernetes 中工作所需要的。 为此，必须安装一个额外的服务 cri-dockerd。 cri-dockerd 是一个基于传统的内置 Docker 引擎支持的项目， 它在 1.24 版本从 kubelet 中移除。 4.安装kubeadm kubelet kubectl 5.拉取所需镜像 6.使用kubeadm创建集群6.1 执行kubeadm init【master结点】 成功的话就是下面的输出 6.2 配置环境变量 查看结点 6.3 node结点加入 执行后，就可以在master结点使用kubectl get nodes发现结点已经加入了 6.4 安装Pod网络插件接下来就是安装Pod网络插件（CNI：Container Network Interface） 这里我们选用flannel作为CNI 首先我们得先下载kube-flannel.yml，可以去它官网flannel下载 这里我也贴出来文件内容，你也可以直接复制 我们可以从文件里看到，这个需要下两个镜像ghcr.io/flannel-io/flannel:v0.26.6和ghcr.io/flannel-io/flannel-cni-plugin:v1.6.2-flannel1 由于网络问题，这个我们可以考虑从自己的电脑上拉取镜像然后传到服务器上 可能用到的命令 这里还要强调下文件里的一个地方 这个Network应该和前面的kubeadm init指定的pod-network-cidr保持一致 前提工作做好后，就可以执行 然后执行 然后你应该就可以看到 可以看到flannel插件已经安装好了，由于coredns的状态和网络插件息息相关，所以flannel插件弄好后，就可以关注coredns 尤其关注coredns的状态是不是Running，如果是的话就说明你成功了 如果没成功，多半是Pending，就说明你网络插件安装的有问题，因为这个coredns和网络插件是强绑定的，只有网络插件可用，它才会从Pending转到Running 此时我们再执行 应该就能看到 结点的状态都是Ready了 6.5 编辑 kube-proxy 配置文件，mode 修改成 ipvs接下来这步我不清楚是否必要 但还是可以做下 重启 kube-proxy","date":"2025-04-19","categories":["k8s"],"tags":["k8s"]},{"title":"Github Action学习[简单使用]","url":"/2025/04/17/GithubAction学习/","content":"Github Action学习[简单使用]一、什么是Github ActionGitHub Actions 是一种持续集成和持续交付 (CI&#x2F;CD) 平台，可用于自动执行生成、测试和部署管道。 你可以创建工作流，以便在推送更改到存储库时运行测试，或将合并的拉取请求部署到生产环境。 二、尝试使用在github创建一个仓库，名为learn_cicd，同时在本地拉取仓库，并创建.github/workflows，添加github-actions-demo.yaml 然后Push上去，在github仓库的actions就可以看到已经成功了 2.1 从示例YAML文件入手，了解语法name name: GitHub Actions Demo 这个指出了工作流的名称 run-name run-name: $ is testing out GitHub Actions 🚀 这个指出了从工作流生成的工作流运行的名称，如果省略了 run-name 或仅为空格，则运行名称将设置为工作流运行的事件特定信息。 例如，对于由 push 或 pull_request 事件触发的工作流，将其设置为提交消息或拉取请求的标题。 此值可包含表达式，且可引用 github 和 inputs 上下文，这里引用的$&#123;&#123; github.actor &#125;&#125; 就是指触发初始工作流运行的用户的用户名 on on: [push] 这个是指出了触发工作流的事件，这里的push是指当推送到工作流存储库中的任何分支时，将运行具有以下 on 值的工作流 常见的写法是 ✅ 含义： 当有人 推送（push）代码到 main 分支 时，就会触发这个工作流。 比如： 你运行 git push origin main 你 merge 了一个 PR 到 main 分支 CI 会自动跑一遍 ✅ 含义： 当有人对 main 分支发起 Pull Request（PR） 时，也会触发工作流。 比如： 你新建了一个从 feature/login → main 的 PR 你更新了这个 PR 的内容（继续 push） CI 也会自动跑一遍，确保 PR 合规 jobs jobs 工作流运行由一个或多个 jobs 组成，默认情况下并行运行。 若要按顺序运行作业，可以使用 jobs.[job_id].needs 关键字定义对其他作业的依赖关系。 每个作业在 runs-on 指定的运行器环境中运行。 显然在这个jobs中只有一个job，为Explore-GitHub-Actions job.[job_id]使用 jobs.[job_id] 为作业提供唯一标识符。 键 job_id 是一个字符串，其值是作业配置数据的映射。 必须将 [job_id] 替换为对于 jobs 对象的唯一字符串。 [job_id] 必须以字母或 _ 开头，并且只能包含字母数字字符、- 或 _。 示例：创建作业 在此示例中，已创建两个作业，其 job_id 值为 my_first_job 和 my_second_job。 job.[job_id].name使用 jobs.[job_id].name 设置作业名称，该名称显示在 GitHub UI 中。 job.[job_id].needs使用 jobs.[job_id].needs 标识运行此作业之前必须成功完成的所有作业。 它可以是一个字符串，也可以是字符串数组。 如果某个作业失败或跳过，则所有需要它的作业都会被跳过，除非这些作业使用让该作业继续的条件表达式。 如果运行包含一系列相互需要的作业，则故障或跳过将从故障点或跳过点开始，应用于依赖项链中的所有作业。 如果希望某个作业在其依赖的作业未成功时也能运行，请在 jobs.[job_id].if 中使用 always() 条件表达式。 示例：要求成功的依赖项作业 在此示例中，job1 必须在 job2 开始之前成功完成，并且 job3 等待 job1 和 job2 完成。 示例：不要求成功的依赖项作业 在此示例中，job3 使用 always() 条件表达式，确保始终在 job1 和 job2 完成（无论是否成功）后运行。 有关详细信息，请参阅“对工作流和操作中的表达式求值”。 jobs.[job_id].runs-on使用 jobs.[job_id].runs-on 定义要运行作业的计算机类型 这里就贴下可以免费使用的 虚拟机 处理器 (CPU) 内存 (RAM) 存储 (SSD) 体系结构 工作流标签 Linux 4 16 GB 14 GB x64 ubuntu-latest、ubuntu-24.04、ubuntu-22.04、ubuntu-20.04 Windows 4 16 GB 14 GB x64 windows-latest、windows-2025、windows-2022、windows-2019 Linux [公共预览版] 4 16 GB 14 GB arm64 ubuntu-24.04-arm，ubuntu-22.04-arm Windows [公共预览版] 4 16 GB 14 GB arm64 windows-11-arm macOS 4 14 GB 14 GB Intel macos-13 macOS 3 (M1) 7 GB 14 GB arm64 macos-latest, macos-14, macos-15 jobs.[job_id].steps作业包含一系列任务，称为 steps。 步骤可以运行命令、运行设置任务，或者运行您的仓库、公共仓库中的操作或 Docker 注册表中发布的操作。 并非所有步骤都会运行操作，但所有操作都会作为步骤运行。 每个步骤在运行器环境中以其自己的进程运行，且可以访问工作区和文件系统。 因为步骤以自己的进程运行，所以步骤之间不会保留环境变量的更改。 GitHub 提供内置的步骤来设置和完成作业。 jobs.[job_id].steps[*].name步骤显示在 GitHub 上的名称。 jobs.[job_id].step[*].run使用操作系统的 shell 运行不超过 21,000 个字符的命令行程序。 如果不提供 name，步骤名称将默认为 run 命令中指定的文本。 每个 run 关键字代表运行器环境中一个新的进程和 shell。 当您提供多行命令时，每行都在同一个 shell 中运行。 例如： 单行命令： 多行命令： jobs.[job_id].step[*].working-directory使用 working-directory 关键字，你可以指定运行命令的工作目录位置。 jobs.[job_id].step[*].uses选择要作为作业中步骤的一部分运行的操作。 操作是一种可重复使用的代码单位。 某些操作需要必须使用 with 关键字设置的输入 简单来说，就直接使用别人打包好的操作 比如 三、小试牛刀我们来测验下，先弄下CI（持续集成），意思就是每次提交代码时，自动检测它是否能成功构建并通过测试。 我们弄个简单的demo main.go gin_test.go .github&#x2F;workflows&#x2F;ci.yaml 这里是直接套模板了 push上去后就可以看到 ok，这样一个简单的CI就完成了 感觉这个工具还是挺方便的😋","date":"2025-04-17","categories":["CI/CD"],"tags":["CI/CD"]},{"title":"如何用interface","url":"/2025/04/16/如何用interface/","content":"如何用interface一、了解下interface的相关知识1、interface是一种类型 首先 interface 是一种类型，从它的定义可以看出来用了 type 关键字，更准确的说 interface 是一种具有一组方法的类型，这些方法定义了 interface 的行为。 go 允许不带任何方法的 interface ，这种类型的 interface 叫 empty interface（空接口）。 如果一个类型实现了一个 interface 中所有方法，我们说类型实现了该 interface，所以所有类型都实现了 empty interface，因为任何一种类型至少实现了 0 个方法。go 没有显式的关键字用来实现 interface，只需要实现 interface 包含的方法即可。 上述例子中，i结构体有一个方法func (ii *i) Get()int 而接口I中只有一个方法Get() int，因为i结构体实现了接口I的所有方法，我们就称i结构体实现了接口I 2、interface 变量存储的是实现者的值 函数f的参数是接口I，而Dog结构体和i结构体都实现了接口I，所以他们都可以被传入函数f中 不难看出两次调用f，分别输出的是d和ii的age字段 在使用 interface 时不需要显式在 struct 上声明要实现哪个 interface ，只需要实现对应 interface 中的方法即可，go 会自动进行 interface 的检查，并在运行时执行从其他类型到 interface 的自动转换 大概了解这些就足够了，如果你想更加了解interface的用法，可以自行搜索 接下来，我们来聊聊接口具体要如何使用 二、接口如何正确地使用Producers and Consumers（生产者和消费者）首先，这句话适用于哪里？这一切都归结为生产者包和消费者包之间的交互。生产者提供一些服务，消费者使用它。这种交互很常见，因为我们通常将代码组织到不同职责的包中。然后，包使用者将依赖于外部包来实现某些功能。 我们将给一个简单的演示来贯穿全文 在db包中， db.go提供了一些持久存储功能。在user包中， user.go包含一些我们想要与用户处理的业务逻辑。在这里， user包将成为consumer，使用db包提供的有状态服务。 Let the consumer define the interfaces it uses（让消费者定义其使用的接口）也就是说，接口应该由consumer来定义，而不是producer 来看下面的代码 这里db.go简单提供了一些插入和读取的方法 消费者user.go需要数据存储的相关依赖才能执行与用户相关的业务逻辑，它不关心存储具体是怎么实现的，而只需要关心它具体需要什么 所以，它只关心它需要2个方法：Insert()和Get()，因此，它能够实现创建和查询用户 因此，它定义了自己的接口UserStore并接收它作为其依赖项，而db.go中的Store结构实现了该接口，所以其可作依赖项 所以说，接受接口就是让消费者在接口中定义他们想要的内容，消费者不用担心谁能实现（我们帮他实现），只需要关注这个接口可以执行消费者需要的任务即可 而这样做，也会带来一些好处： 更松散的耦合，以及更灵活 通过接受接口，消费者不会与其依赖关系耦合。如果明天我决定使用 MySQL 而不是 Postgres，则user.go根本不需要更改。只要满足消费者定义的接口，这就保留了使用任何存储的灵活性。 更容易测试 测试也会变得更简单，因为我们可以轻松地传递内存中的模拟，而不必启动实际的数据库实例，这对于单元测试来说可能会很麻烦。我们可以拥有一个模拟内存存储，其中包含测试用例所需的适当数据。 Producers return concrete types（生产者返回具体的类型）也就是说，producer应该向consumer提供具体的类型而不是接口 为什么呢？ producer不一定只为某个consumer提供服务，如果很多consumer都需要用到producer中的方法（以接口的形式），那producer就得为每个consumer都返回某个特定的接口，但这就违背了我们返回接口的目的 上面的示例中，NewDB()返回具体类型给消费者，而消费者可以隐式地将 *Store转化为UserService，其他消费者也同理，这样就可以利用这个机制，免去了为了适配各个接口的New过程 我们这里，也会给出这个Bad Case 该接口现在由生产者定义，消费者使用该接口作为入口点。这被称为抢占式接口，即生产者在实际使用接口之前抢先定义接口。 有些人可能会认为，让生产者返回一个接口，可以让开发人员专注于函数发出的 API。然而，这在 Go 中是不必要的；隐式接口允许在事后进行优雅的抽象，而不需要你预先进行抽象。 Do not define interfaces before they are used: without a realistic example of usage, it is too difficult to see whether an interface is even necessary, let alone what methods it ought to contain.（在使用接口之前不要定义它们：如果没有实际的使用示例，很难看出接口是否必要，更不用说它应该包含哪些方法了）如果没有实际的使用示例，就很难看出接口是否必要，更不用说它应该包含哪些方法了。 这里涉及到了，应该先编写接口还是先编写实例的问题 假设先编写实例，这当然可以，你可以把它可能有的方法全部列举出来，比如对于一个数据库实例，如上面的Store类型，它肯定是有CRUD这4个方法的，但是有些情况，我们却不需要U（update），那你写的方法就没用了 假设先编写接口，像上面的user那样，它清楚自己需要什么，但这对我们编写代码有什么帮助呢？很简单，借助interface，我们在写它的相关服务的时候，就很清楚如何去编写，不需要考虑谁来实现（因为我们后面肯定会实现的），这样，我们就可以很轻松地完成这个服务的逻辑（因为我们有任何我们需要的方法，没有可以自己添加嘛），后续我们只需要专注于如何实现那些接口就可以了 上面实际上是两种方向，自下而上，自上而下 自下而上固然可行，但是它缺乏了对全局的把控，因为你的高度低了，你只能把控你自己以及比你低一层级的，这会让你前期虽然写的很爽，但后期会花费大量的时间修改代码 而自上而下，拥有较为广阔的视野，因为我们，清楚自己需要哪些方法，由此，来决定下层的走向，这种编写方式，理论上可以，越写越爽，越爽越写，从此在coding的路上一去不复返😜 参考文献：https://go.dev/wiki/CodeReviewComments#interfaces https://sanyuesha.com/2017/07/22/how-to-understand-go-interface/","date":"2025-04-16","categories":["golang"],"tags":["golang","interface"]},{"title":"关于我","url":"/about/index.html","content":"GitHub","date":"2025-04-16"},{"title":"分类","url":"/categories/index.html","content":"","date":"2025-04-16"},{"title":"归档","url":"/archives/index.html","content":"","date":"2025-04-16"},{"title":"标签","url":"/tags/index.html","content":"","date":"2025-04-16"},{"title":"search","url":"/search/index.html","content":"","date":"2025-04-16"}]